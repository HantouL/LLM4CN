{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Best function on Jazz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import networkx as nx\n",
    "from scipy.sparse.linalg import eigsh\n",
    "\n",
    "def score_nodes(adj_matrix):\n",
    "    adj_matrix = np.array(adj_matrix)\n",
    "    G = nx.from_numpy_array(adj_matrix)\n",
    "    LCC = G.subgraph(max(nx.connected_components(G), key=len))\n",
    "\n",
    "    eigenvalues, eigenvectors = np.linalg.eig(adj_matrix)\n",
    "    max_eigenvalue_index = np.argmax(eigenvalues)\n",
    "    eigenvector = eigenvectors[:, max_eigenvalue_index]\n",
    "    normalized_eigenvector = eigenvector / np.sum(eigenvector)\n",
    "\n",
    "    ii = {v: i for i, v in enumerate(LCC.nodes())}\n",
    "    L = nx.normalized_laplacian_matrix(LCC)\n",
    "    eigenvalues, eigenvectors = eigsh(L, which='SM', maxiter=1000 * L.shape[0])\n",
    "    Fiedler = eigenvectors[:, 1]\n",
    "\n",
    "    H = nx.Graph([(u, v) for u, v in LCC.edges() if Fiedler[ii[u]] * Fiedler[ii[v]] <= 0.0])\n",
    "    for v in H.nodes():\n",
    "        H.nodes[v]['weight'] = 1.0 / H.degree(v)\n",
    "    cover = list(nx.algorithms.approximation.min_weighted_vertex_cover(H))\n",
    "    max_degree = max([G.degree(v) for v in G.nodes() if v not in cover])\n",
    "    min_weight = min(H.nodes[v]['weight'] for v in H.nodes())\n",
    "    scored_nodes = {}\n",
    "    for v in G.nodes():\n",
    "        if v in cover:\n",
    "            scored_nodes[v] = H.nodes[v]['weight']\n",
    "        else:\n",
    "            scored_nodes[v] = normalized_eigenvector[v] * min_weight\n",
    "    return scored_nodes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Best function on Network_Science"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "\n",
    "def score_nodes(adj_matrix):\n",
    "    G = nx.Graph(adj_matrix)\n",
    "    \n",
    "    score1 = {node_id: 0.0 for node_id in G.nodes()}\n",
    "    for u, v in G.edges():\n",
    "        degree_u = G.degree(u)\n",
    "        degree_v = G.degree(v)\n",
    "        score1[u] += 1.0 / degree_u if degree_u != 0 else 0.0\n",
    "        score1[v] += 1.0 / degree_v if degree_v != 0 else 0.0\n",
    "    \n",
    "    betweenness = nx.betweenness_centrality(G)\n",
    "    pagerank = nx.pagerank(G)\n",
    "    \n",
    "    weight_degree = 0.2\n",
    "    weight_betweenness = 0.3\n",
    "    weight_pagerank = 0.5\n",
    "    \n",
    "    scored_nodes = {}\n",
    "    for node_id in G.nodes():\n",
    "        score = (weight_degree * score1.get(node_id, 0) +\n",
    "                 weight_betweenness * betweenness[node_id] +\n",
    "                 weight_pagerank * pagerank[node_id])\n",
    "        scored_nodes[node_id] = score\n",
    "    \n",
    "    return scored_nodes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Best function on Twitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import networkx as nx\n",
    "from scipy.sparse.linalg import eigsh\n",
    "\n",
    "def score_nodes(adj_matrix):\n",
    "    G = nx.from_numpy_array(adj_matrix)\n",
    "    score1 = {node_id: 0.0 for node_id in G.nodes()}\n",
    "    for u, v in G.edges():\n",
    "        score_u = score_v = 0.0\n",
    "        degree_u = G.degree(u)\n",
    "        degree_v = G.degree(v)\n",
    "        if degree_u != 0:\n",
    "            score_u = 1.0 / degree_u\n",
    "        if degree_v != 0:\n",
    "            score_v = 1.0 / degree_v\n",
    "        score1[u] += score_u\n",
    "        score1[v] += score_v\n",
    "    betweenness = nx.betweenness_centrality(G)\n",
    "    pagerank = nx.pagerank(G)\n",
    "    closeness = nx.closeness_centrality(G)\n",
    "    scored_nodes = {node_id: 0.0 for node_id in G.nodes()}\n",
    "    for node_id in G.nodes():\n",
    "        scored_nodes[node_id] = (0.2 * score1.get(node_id, 0) +\n",
    "                           0.3 * betweenness[node_id] +\n",
    "                           0.5 * pagerank[node_id] +\n",
    "                           0.4 * closeness[node_id])  # Additional metric\n",
    "    \n",
    "    # Algorithm 2 modifications\n",
    "    G1 = G\n",
    "    G2 = nx.from_numpy_array(np.where(adj_matrix > 0, 1, 0))\n",
    "\n",
    "    centrality1 = nx.betweenness_centrality(G1)\n",
    "    centrality2 = nx.betweenness_centrality(G2, normalized=True)\n",
    "\n",
    "    for node, centrality in centrality1.items():\n",
    "        scored_nodes[node] += centrality + centrality2[node]\n",
    "\n",
    "    LCC1 = G1.subgraph(max(nx.connected_components(G1), key=len))\n",
    "    LCC2 = G2.subgraph(max(nx.connected_components(G2), key=len))\n",
    "\n",
    "    L1 = nx.laplacian_matrix(LCC1)\n",
    "    L2 = nx.laplacian_matrix(LCC2)\n",
    "\n",
    "    eigenvalues1, eigenvectors1 = eigsh(L1.astype(np.float32), k=2, which='SM')\n",
    "    eigenvalues2, eigenvectors2 = eigsh(L2.astype(np.float32), k=2, which='SM')\n",
    "\n",
    "    Fiedler1 = eigenvectors1[:, 1]\n",
    "    Fiedler2 = eigenvectors2[:, 1]\n",
    "\n",
    "    H1 = nx.Graph()\n",
    "    H2 = nx.Graph()\n",
    "\n",
    "    for u, v in LCC1.edges():\n",
    "        if Fiedler1[list(LCC1.nodes()).index(u)] * Fiedler1[list(LCC1.nodes()).index(v)] <= 0.0:\n",
    "            H1.add_edge(u, v)\n",
    "\n",
    "    for u, v in LCC2.edges():\n",
    "        if Fiedler2[list(LCC2.nodes()).index(u)] * Fiedler2[list(LCC2.nodes()).index(v)] <= 0.0:\n",
    "            H2.add_edge(u, v)\n",
    "\n",
    "    for v in H1.nodes():\n",
    "        scored_nodes[v] += 1.0 / H1.degree(v)\n",
    "\n",
    "    for v in H2:\n",
    "        degree = nx.degree(H2, v)\n",
    "        scored_nodes[v] += np.log1p(1.0 / degree) if degree > 0 else 0\n",
    "\n",
    "    cover1 = nx.algorithms.approximation.min_weighted_vertex_cover(H1)\n",
    "    cover2 = nx.algorithms.approximation.min_weighted_vertex_cover(H2)\n",
    "\n",
    "    for v in cover1:\n",
    "        scored_nodes[v] += 1\n",
    "\n",
    "    for v in cover2:\n",
    "        scored_nodes[v] += np.log1p(nx.degree(G2, v))\n",
    "\n",
    "    max_score = max(scored_nodes.values())\n",
    "    min_score = min(scored_nodes.values())\n",
    "\n",
    "    for node in scored_nodes:\n",
    "        if max_score != min_score:\n",
    "            scored_nodes[node] = (scored_nodes[node] - min_score) / (max_score - min_score)\n",
    "        else:\n",
    "            scored_nodes[node] = 0\n",
    "\n",
    "    return scored_nodes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Best function on Synthetic Network (BA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import numpy as np\n",
    "from scipy.sparse.linalg import eigsh\n",
    "\n",
    "def score_nodes(edge_matrix):\n",
    "    G = nx.from_numpy_array(edge_matrix)\n",
    "    max_pagerank = max(nx.pagerank(G).values())\n",
    "    LCC = G.subgraph(max(nx.connected_components(G), key=len))\n",
    "    ii = {v: i for i, v in enumerate(LCC.nodes())}\n",
    "    L = nx.normalized_laplacian_matrix(LCC)\n",
    "    eigenvalues, eigenvectors = eigsh(L.astype(np.float32), k=2, which='SM', maxiter=1000 * L.shape[0])\n",
    "    Fiedler = eigenvectors[:, 1]\n",
    "    H = nx.Graph([(u, v) for u, v in LCC.edges() if Fiedler[ii[u]] * Fiedler[ii[v]] <= 0.0])\n",
    "    for v in H.nodes():\n",
    "        H.nodes[v]['weight'] = 1.0 / H.degree(v)\n",
    "    cover = list(nx.algorithms.approximation.min_weighted_vertex_cover(H, weight='weight'))\n",
    "    max_degree = max([G.degree(v) for v in G.nodes() if v not in cover])\n",
    "    min_weight = min(H.nodes[v]['weight'] for v in H.nodes())\n",
    "    scored_nodes = {}\n",
    "\n",
    "    for node_id in G.nodes:\n",
    "        node_neighbors = G[node_id]\n",
    "        norm_betweenness = sum([edge_matrix[node_id][neighbor] for neighbor in node_neighbors]) / np.sum(edge_matrix)\n",
    "        score = (0.5 * norm_betweenness) + (0.5 * (nx.pagerank(G)[node_id] / max_pagerank))\n",
    "        if node_id in cover:\n",
    "            score += min_weight\n",
    "        else:\n",
    "            score *= G.degree[node_id] / max_degree\n",
    "            score *= min_weight\n",
    "        scored_nodes[node_id] = score\n",
    "\n",
    "    pagerank_scores = nx.pagerank(G, weight='weight')\n",
    "    betweenness = nx.betweenness_centrality(G)\n",
    "    \n",
    "    for node in G.nodes:\n",
    "        node_neighbors = G[node]\n",
    "        norm_betweenness = np.sum([(edge_matrix[node][neighbor] / np.sum(edge_matrix[neighbor])) for neighbor in node_neighbors])\n",
    "        score = pagerank_scores[node] + (2 * np.log10(betweenness[node] + 1)) + (0.5 * norm_betweenness)\n",
    "        scored_nodes[node] += score\n",
    "\n",
    "    return scored_nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch-1.9.0-cu102-py39",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
